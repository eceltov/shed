undo/do/redo:
    saving information for reversibility:
        It is sufficient for delete operations to save the characters they deleted. If a new operration arrives that should be executed before some of the operations
        in the local HB, the reverse operations are applied, than the new operation and then the following operations in HB are redone and their inverses remade.

inverse examples:
    - 0: 
        The inverse of subdif 0 is adding all content from row 1 to row 0, then deleting the content from row 1 and the row itself.
    - -1:
        The inverse of -1 is 1
    - [2, 4, 3]:
        For content '123456' the inverse is [2, 4 - 3, '234'], where '234' = '123456'.substr(4 - 3, 3)
    - 0 both ways:
        The inverse of 0 is pushing the content from 1 to zero and deleting 1. The reverse of that is adding 1, adding content from 0 to 1 and deleting content from 0. This is equal to subdif 0.

interval_inverse_buf notes:
    if the difs 1, 2, 3, 4 are pushed in this order to interval_buf and each consists of subdifs x_1, x_2, x_3, than the content of interval_inverse_buf should be:
        [-4_3, -4_2, -4_1, ..., -1_1], where -x is an inverse of x where -x = to.merge(-x_3, -x_2, -x_1)
        -> 	the interval_inverse_buf has the subdifs reversed, but if the "subdif segment" consists of more steps, they have to be in proper (not reversed order), therefore
		while producing the inverse dif, if one subdif requires multiple steps for inversion, these steps are added in the reverse order, so they will later be reversed to the correct order.
	applyDif(1) produces the pseudo inverse dif: [-1_1, -1_2, -1_3], if the contents are added to the interval_inverse_buf, that reversed and than merged, the resulting dif is the inverse of the starting dif.
	


reformating:
    Necessary because the App component receives external difs. These difs have to have their inverses. The inversion function has to have access to rows in the TextContainer component
    in order to create inverses, as well as access to the external difs received in the App component. 
    - rows will be pushed to the App component
    - rows will have to be added in props to the TextContainer component
    - each change would prompt a new rendering of TextContainer and thus copying all rows:
        Solutions:
            1. Only a limited set of rows will be pushed to TextContainer (same problem, only smaller)
            2. TextContainer will be merged will App, App would render Rows directly

undo/do/redo example:
    user 0 writes 'a' (before user 1) and user 1 writes 'b' to an empty document, and user 1's message arrives first to the server (0 has a CS latency of 1 second).
    user 0 receives 1's message before his is even sent. Because 0's change is already present in HB and the local doc state and his userID is lower,
    the document should contain 'ab'. After some time user 1 receives the 'a' and his doc state changes from 'b' to 'ab'.

    user 0 site:
        the document has the state of 'a' with one member in HB and HB_inverse. He receives the message from 1 and the undo/do/redo option is chosen. The ancestor index should be -1.
        Because the total ordering decides that 'a' should precede 'b', the index of the HB entry for 'a' is 0 and for 'b' is 1. All entries with index 1 or more in the local HB
        will be removed (none exist though). Than the 'b' is 'done' by increasing its position by the length of 'a'.



redo (switch based on incoming external subdif):
    - add:
        - add: only changes subdifs on the same row with the same or greater position, example:
            doc state: "123" subdifs add(x, 1, "aaa"), add(x, 5, "bbb"), external subdif preceding both: add(x, 2, "c")
            doc state history: "123", "1aaa23", "1aaa2bbb3", "1aaa2cbbb3"
            changed subdifs: add(x, 1, "aaa"), add(x, 6, "bbb")
          all positions greater or equal to the external subdif add will be increased by the external subdifs content length
        - del: subdifs on same row with lower position are unchanged, with greater or equal are increased by the external subdif's length, example:
            doc state: "123" subdifs del(x, 1, 1), del(x, 2, 1), external subdif preceding both: add(x, 2, "b")
            doc state history: "123", "23", "2", "2b"
            changed subdifs: del(x, 1, 1), del(x, 3, 1)
        - newline: unchanged
        - remline: remlines will be deleted? ///TODO
        - move: move the target or source (or both) positions if they are same or greater
    - del:
        - add: example:
            doc state: "123" subdifs add(x, 1, "aaa"), add(x, 5, "bbb"), external subdif preceding both: del(x, 2, 1)
            doc state history: "123", "1aaa23", "1aaa2bbb3", "1aaabbb3"
            changed subdifs: add(x, 1, "aaa"), add(x, 4, "bbb")
        - del: example:
            doc state: "123" subdifs del(x, 1, 1), del(x, 2, 1), external subdif preceding both: del(x, 2, 1)
            doc state history: "123", "23", "2", ""
            changed subdifs: del(x, 1, 1), del(x, 1, 1)
          if the dels in redo would delete something that does not exist, it is fine (because the external subdif deleted it)
        - newline: unchangedj12j
        - remline: impossible to happen, handled in del del
    - newline:
        - add: the add subdifs will have their row attribute incremented (if greater or equal to newline)
        - del: the del subdifs will have their row attributes incremented (if greater or equal to newline)
        - newline: increment the newline by one (alternative idea is to remove the newline if it targets the same row, but what if the intention of the external newline is to create a new row and write new content on it?)
        - remline: increment the remline by one (if greater or equal to newline)
    - remline:
        - add: ///TODO
        - del: impossible
        - newline: decrease the newline by one if the value of remline is less or equal to? ///TODO
        - remline: if the remline numbers are equal, then remove the remline in HB (///TODO), the reason is that both users want to remove the same row and no other,
                   else decrement the HB remline if the external points to a lower line


complications with the linear history buffer (no state array):
    let there be client 0 and 1. 0 has a big CS latency and makes a change. 1 makes 2 changes (sends 2 messages) before 0's message arrives.
    0 receives the first message and transforms it using the undo/do/redo scheme, but he won't transform the second one, because the metadata does not make it clear, if it is 
    independent of 0's change (the second message of 1 is dependant on his first, the first is the only which shares the doc state with 0's message).

    the solution is 0's own message that is sent back to him. Every preceding message has to be transformed until 0's message is received by 0. This can be done by adding
    an array of unreceived messages. 

    if a received external message was created after a local message was sent but before it was received, the undo/do/redo scheme is used

    UPDATE: the above does not handle situations, where client 1 has big SC latency, thus user 0's message could already arrive to him, but user 1 does not have it.
    User 1 thus creates those 2 messages, 0 receives it and the messages state that they are dependant on some state. If 0's message is older in HB than that state,
    1's messages won't be transformed against 0's message.

    SOLUTION: Server ordering. Each client will have an array of incoming server messages metadata so the server ordering is known. HB contains the total ordering,
    not the server ordering. HB's total ordering allows for local changes to take efect immediately, the server ordering could not do that.

complications with newline transformations:
    assume the state "123", user 0 adds 2 newlines between '2' and '3' with latency, whilst user 1 deletes '3'. Given the current add, del, newline, remline model,
    there is not enought information to transform the delete '3' instruction, as newline movement is encoded as del '3', newline, add '3' (there is no direct connection
    between the content of del and add).

    A new instruction move(source_row, source_position, target_row, target_position, length) is considered, moving a specific amount of characters to a different position.
    The same scenario would be: User 0 dif: [1, 1, [0, 2, 2, 0, 1]], user 1 dif: [[0, 3, 1]]. After transformation, user 1's dif would be [[2, 1, 1]].


Operations and orderings:
    Each operation has a dependancyNumber, which is equal to the number of entries in server_ordering during generation. The only operations that may not be present
    in server_ordering but be present in the document state are local operations, as external operations are immediately logged to server_ordering.
    Thus, if a user receives an external operation, he can deduce that it is dependant on all server_ordering entries based on dependancyNumber plus all operations
    made by the same user, which were received earlier than this message (due to all messages from one source being sent in the order of generation).
    The receiver thus has to use the full GOT control algorithm to undo all independant and dependant (from the same user) operations up to dependancyNumber, transform the
    incoming message and apply them back.

    The dependancyNumber may not be implemented, as it is bacivally the prev_userID and prev_commitSerialNumber.

    Is the HB even neccesary? Yes it is because it holds the transformed operations (the document state).

Ideas:
    Implement "blaming". A mode that shows what content was authored by what users.

Possible problem:
    An operation A is transformed into two using some include/exclude transformation into A'_1 and A'_2.
    Another operation B is transformed into B' by excluding A and has relative addressing.
    Later B'' is created by including A'_1 and A'_2, but it is relatively addressed to A, therefore one of the A's need to have the same id as A. 

makeIndependant():
    It is not possible to call LIT on the incoming message dif directly, because msgDif[0]->msgDif[1]->... and LIT includes transformedMsgDif[i]
    into the transformation dif when transforming msgDif[i + 1]. Therefore all previous subdifs would be included multiple times. to solve this,
    the subdifs in msgDif are made independant, so that the transformed subdifs can be included in the transformation.

    Similarly, it is not possible to call LET on any wDif, whose wSubdifs are not independant. If LET were to be called on dependant wSubdifs,
    first some operations would be excluded from the first wSubdif (given the precondition that wTransformationDif[0]->wSubdif), but for
    the next wSubdifs the precondition would not hold, as they are dependant.

Mutual independancy:
    When excluding a list of subdifs from a dif (aka LET(dif, subdifs)), the dif should be independant to satisfy the precondition.
    After the exclusion, all of the subdifs in dif will be independant, as they were made independant to satisfy the precondition and
    they could not be made dependant during exclusion. If the excluded dif will be later used in a inclusion transformation as the transformer,
    the dif should be made dependant.

    The rule of thumb: LET(mutually independant, mutually dependant) => mutually independant
                       LIT(mutually independant, mutually dependant) => mutually dependant

ET_MN:
    If a move subdif is dependant on a newline subdif so that subdif[2] == newline, excluding the newline subdif from move will cause
    the move operation to lose information, as the move target row is nonexistent. The IT_MN function therefore has to check is some
    information was lost.

    Generalization: If any operation takes place on a row that was added previously (basically any operation not on row 0), then excluding
    that newline subdif makes the operation lose information.

    Example: If we were to add a new row 1 and add some text on in and then decided to split that row by the Enter key, than the dif would
    look something like this: [1, [1, 0, "text"], 2, [1, 2, 2, 0, 2]] (leaving "te" on row 1 and moving "xt" on the next row).
    Making that dif independant will transform the move subdif in the following way: First, the addition part will lose information
    due to the newline being excluded. Next the deletion part will lose information, as the text it was about to delete will be removed.
    It was observed that when splitting lines with Enter a move subdif will always be preceded by a newline, but when deleting rows
    and moving the text of the deleted row to the previous one, no newline precedes, therefore the move operation's information loss
    needs to be seperated into the addition and deletion parts.

Relative message chains:
    Let there be clients 0 and 1. 0 creates a new line via subdif 1. Client 1 receives this subdif and decides to remove the line via 
    subdif -1. Before 1's message arrives to 0, 0 adds some text on line 1 via subdif [1, 0, "text"].

    If there were no other clients that would send messages in between, both 0's messages would be part of a message chain and therefore 
    1's message would be totally ordered after both 0's messages and because it would attempt to delete a non empty line, it would be omitted.

    If, however, some other clients were to send messages in between 0's messages, so that 0 receives a foreign message and after that
    sends the second subdif [1, 0, "text"] (the foreign message would not interfere with 0's intend in any way), then 0's messages
    would not be part of a message chain, because they do not depend on the same state.

    Relative message chains attempt to fix that. Instead of a message chain being absolute, it would be relative in the sense that,
    in the case of the above example, if 0's messages are not in a message chain BUT 1's message did not break the fact that it would
    be a message chain (some other client broke it), than 0's messages would appear as a message chain for the purpose of processing
    1's message.

    Implementation:
        From 0's perspective: 1's message is not present in the server_ordering linked to 0's second message, therefore 1's
        message could not break 0's message chain.

        From 1's perspective: First, 1's document state will have the line deleted, because 0's second message did not arrive yet.
        After it's arrival, it's server_ordering does not contain 1's message and therefore it could not breake the message chain.

        From 2+'s perspective: Same as 1's perspective, because 1's message will arrive first.

Garbage collection scheme:
    (this section does not have consistent naming, dependency and metadata timestamp refer to basically the same thing)
    Operations stored in HB that will certainly not be used in any following transformations can be treated as garbage, as they
    do not add any value but take up space and slow down the algorithm (as it traverses the HB).

    The solution is for the server to send a prompt to all users to send it back the information about their last received message
    from the server (metadata of the last member in the local SO). The server collects all answers, selects the metadata pointing
    at the oldest message (according to SO) and send all users a message saying that everything older than the selected metadata
    is garbage.

    This scheme works for the following reasons:
        In case there were no message chains (no user can send two messages after one another unseperated by an incoming message from server): 
            After a user sends the requested metadata to the server, all of his following messages will have the same of newer metadata
            timestamp (the last two members of the metadata structure, representing the local SO state).
            That means that after the server collects all the requested metadata and selects the oldest one, all following messages it receives
            will have a newer (or same) metadata timestamp. Therefore, all operations in HBs with an older timestamp can be removed, as they
            are independant of all following messages. Those with the same timestamp are dependant on the operation with that timestamp.

            Special case: What about local unreceived messages with a older timestamp?
                The problem is that when a user send a local message A and receives a foreign one B, then receives the server prompt to send the
                metadata, the server could select the metadata of B. That means that the server wants the user to delete everything older that B,
                that could also include dependencies of A. The user would later receive A and could not process it because it would not known
                it's dependencies.

                However, this is not a problem. This is because before the user receives the information about what operations to delete from HB, 
                the user will have already received message A, because it was sent before the response to the server's prompt and therefore
                it had to be received before the instruction to garbage collect.

        In case there were message chains:
            Similarily to the previous case, local message chains are not a problem because any unreceived local message chains older than the
            sent metadata to the server will be received before the garbage collection instructions and local message chains send after sending 
            the metadata to the server (case when a local message chain started and the server prompt was received in the middle of the chain)
            will still have it's dependency untouched, as the server instructs to delete messages older than the oldest metadata (possibly the
            local message chains dependency), therefore the local chain's dependency will be untouched.

            Foreign message chains will also not cause problems, because:
                If the foreign message chain's dependancy is older than the one sent by the local user to the server, it will not cause a problem,
                because the foreign user therefore sent a some older dependancy to the server (possibly, or he sent a newer, but then he will receive
                his old message chain prior to the garbage collection instruction. The local user will also receive the foreign message chain prior to the
                GC instruction, because the server sends it after collecting information from all users, by which point he had to receive the foreign message
                chain and sent it already to the local user.)

                If the foreign message chain's dependancy is the same or newer than the one send by the local user to the server, it is not a problem at all.
                It's dependancy will not be garbage collected.

    Implementation details:
        How to get rid of the garbage? (Let garbage refer to all operations that should be garbage collected.)
            For the server, this is as easy as simply deleting all operations up to the selected metadata.

            For the client this should also be the case, for the same reasons discussed in why the GC scheme works, as the only difference to the server's
            HB is that it contains yet unreceived local operations.

        Optimalization: 
            Clients do not have to send all metadata about the oldest message, but only it's index in SO. However, clients do not have to have the same SO,
            because some took part in GC and some not, therefore instead of an index, it would be the total message serial number.

    Handle special cases:
        User disconnects in critical parts of the scheme:
            If a client disconnects after he was added to the garbageRoster (array of userIDs of clients partaking in GC), his userID has to be removed
            from the garbageRoster, so that the server does not wait for his response.
        
        A new user joins after the server sends out the prompt:
            Simply do not include new clients in the process. Handle them the next time the GC is invoked.

    THIS DOES NOT WORK:
        Basing the GC on the last message present in clients' SO is insufficient (basing it on the first two entries of the metadata), because of unreceived external
        messages with an earlier timestamp. The solution is to base it on the latter two entries in the metadata. 

        The algrithm above proposed to base the GC on the userID and commitSerialNumber of the last SO entry, but it should be based in the previousUserID and
        previousCommitSerialNumber, because that is the oldest SO entry that is depended on.

Persistent server state scheme:
    In order for the server to be able to hold any state, all the GOTCA algorithms need to be added. The servers document state has to be stored in order to be
    sent to newly joined users. The server will therefore relay messages to other users and run the message through the algorithms to update it's state.
    The server state can be a simple array of strings representing rows. The state should also be recorded in a file from time to time, to prevent outages
    and to make the state persistent during runtimes.

App structure:
    The app has to allow concurrent runs of multiple file instances, therefore a central controler has to be implemented, that will start the individual
    'servers'.

Async:
    Given the situation when a client receives messages and GCMetadataRequests, even if the request was sent after all messages by the server, the request can
    be processed by the client before all messages had been processed.

    Implications:
        - One run of GC can collect less messages, this could be fixed by some message serialization, but then the client would send the request after all the
        previous messages had been processed, which could lead to timeouts.

    Example:
        The server starts the GC process after 5 messages. 7 clients send a message at the same time, writing a character at the first position. The server
        receives them at the same time. The server relays the first 5 messages, then starts the GC process, sends the GC requests and then sends the remaining
        two messages. The clients process 2 messages, then send a GC response to server. The server determines that the 2nd message is the GC breakpoint and
        sends the clients the information. The clients have processed the first 6 messages but then the GC prompt arrives, so they delete the first message.
        Then they receive the last 7th message, but it is not transformed the right way. Instead of it being [0, 6, '6'], it's [0, 0, '6']. It is because
        the dif [0, 0, '6'] is being transformed agains difs [0, 1, '1'], [0, 2, '2'],... but not agains [0, 0, '0'], because it was deleted.

        The jist of the problem: What if several clients send a message from the same state, but after some of these messages arrive, the GC is triggered and
        some of these messages, that have been already processed by clients, are deleted and the rest of messages can't be transformed correctly?

        Solution: The problem is in the implementation, not the theory. The client GC responses need to be based on the metadata the last SO entry is dependant on,
        not on the last SO entry itself.

Consultation notes:
    Each node server should host multiple documents, the overhead of starting a node server for each document is too high and there is only a limited amount
    of ports. The amount of ports should be as low as possible. Therefore, some extra information has to be added to websocket transaction for authentication.

    Data can either be stored in an SQL database (GraphQL) or locally. Local storage has the advantage of straightforward file access and no API call overhead,
    but has disadvantages, like multiple resources being accessed at the same time (metadata read/write), which could result in race conditions and blocking.
    A database has the advantage of atomicity, but could be overkill for this project.

    A PHP front controller is probably not a good idea, compared to everything being handled by Node.js, because the bulk of the project is already written in JS.
    The CAS authentication would be handled in PHP, but the rest can be done in Node. This would result in a SPA design.

Client Refactoring:
    The client shall be refactored into individual modules:
        Workspace Module, that initializes others, initializes the WebSocket connection, wraps it and passes it to others.
        Editor Module, that contains a single document represented in the editor and handles all the neccessary editing communication.
        File Directory Module, that allows to browse, view, create, rename and delete files in a workspace.

    Component communication:
        The main module only passes the wrapped communication to the editor component and the file directory component. There is no communication between components.

    Communication:
        The client will only have one WebSocket connection to the server. It will start by client authentication and authorization, after that
        the server will send the workspace structure to the client. The client can then open a document. The server will send the document to the client and mark,
        that the client has that document opened, meaning he will receive changes made to the document. After the client closes the document, the server will remove it
        from the local client metadata and stop sending him messages of that document.

        Each message will also have to have a documentID in the operation metadata, which will effectively be a hash to a given file within the workspace (the hash needs to be random for security!).

    Workspace Module:
        It will wrap the connection it the following way: 
            The onmessage callback will be a swich that will invoke other callbacks specified by the editor and file directory components. This way the message does not need to be passed via props to React Components.

    Editor Module:
        It will contain all the opened document session (Ace editor sessions). After the editor message callback is invoked, it will check what document is targeted. Then it will pass that session to the GOTCA.

    File Operations Message Format:
        The messages sent by the client to the server with the goal of manipulating files will have the following format:
            [msgType, fileID, arguments...], where fileID is the ID specified in the file structure, msgType is one of the enums specified in lib/communication.js and arguments are new names for the file if neccessarry.
            fileID is the target file for delete and rename operations, or the parent folder for create operations.

4 subdif model vs 5 subdif model:
    Situation: The local client pressed enter in the middle of a line, but after that, an external operation arrives, where the other client
    Did the same but moved only a smaller part of the line away.
        Original line: Some longer text
        Move behaviour:
            Local client's dif would look like: [1, [0, 5, 1, 0, 11]], external client's would look like: [1, [0, 12, 1, 0, 4]].
            After LIT, the local client's dif would be: [2, [0, 5, 2, 0, 7]].

            Document state:
                Some 
                text
                longer 
        Merged move/newline behaviour:
            Local client's dif would look like: [0, 5], external client's would look like: [0, 12].
            Some longer 
            text

            Some 
            longer text

            Some 
            longer 
            text
